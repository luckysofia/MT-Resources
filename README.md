# NMT-Resources

## Github资源：
1. https://github.com/NiuTrans/MTBook
2. https://github.com/THUNLP-MT/MT-Reading-List
3. https://github.com/fighting41love/funNLP
4. https://github.com/InsaneLife/ChineseNLPCorpus
5. https://github.com/brightmart/nlp_chinese_corpus
6. https://github.com/THUNLP-MT/THUMT
7. https://github.com/tensorflow/addons（用于tf2.0升级）
8. https://github.com/tensorflow/models
9. https://github.com/tensorflow/nmt
10. https://github.com/harvardnlp/annotated-transformer
11. https://github.com/tensorflow/tensorflow
12. https://github.com/tensorflow/tensor2tensor
13. https://github.com/OpenNMT/OpenNMT-tf
14. https://github.com/google/sentencepiece
15. https://github.com/rsennrich/subword-nmt
16.	https://github.com/fxsjy/jieba

## 网页资源：
1. http://www.52nlp.cn/statistical-machine-translation-tutorial-reading
2. https://www.jiqizhixin.com/articles/2017-08-22-6
3. https://www.zhihu.com/question/65340310
4. https://www.cnblogs.com/zhbzz2007/p/6276712.html
5. https://blog.csdn.net/csdnnews/article/details/79662331
6. https://cloud.tencent.com/developer/article/1443493
7. https://cloud.tencent.com/developer/article/1443492
8. https://paperswithcode.com/area/natural-language-processing
9. http://matrix.statmt.org/matrix
10. https://chinesenlp.xyz/#/zh/docs/machine_translation
11. https://www.jiqizhixin.com/articles/2019-09-05-2
12. https://zhuanlan.zhihu.com/p/22701208
13. https://www.jianshu.com/p/f2bd4e4a391b
14. https://jalammar.github.io/illustrated-transformer/
15. https://zhuanlan.zhihu.com/p/53682800
16. http://nlp.seas.harvard.edu/2018/04/03/attention.html
17. https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html
18. https://mp.weixin.qq.com/s/axAOxQ2RPBB0L6V_ok6GPw

## 论文资源：
### SMT:
1. A Statistical Approach to Machine Translation
2. The Mathematics of Machine Translation: Parameter Estimation
3. A Statistical MT Tutorial Workbook
4. Improved alignment models for statistical machine translation
5. A phrase-based, joint probability model for statistical machine translation
6. Discriminative Training and Maximum Entropy Models for Statistical Machine Translation
7. Statistical Phrase-Based Translation
8. A Hierarchical Phrase-Based Model for Statistical Machine Translation
9. Tree-to-String Alignment Template for Statistical Machine Translation

### NMT：
1. Recurrent Continuous Translation Models 
2. Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation
3. Neural machine translation by jointly learning to align and translate
4. On the Properties of Neural Machine Translation: Encoder–Decoder Approaches
5. Sequence to sequence learning with neural networks
6. Addressing the rare word problem in neural machine translation
7. Effective Approaches to Attention-based Neural Machine Translation
8. On using very large target vocabulary for neural machine translation
9. Google's neural machine translation system: Bridging the gap between human and machine translation
10. Minimum Risk Training for Neural Machine Translation
11. Neural Machine Translation of Rare Words with Subword Units
12. A convolutional encoder model for neural machine translation
13. Convolutional Sequence to Sequence Learning
14. Attention Is All You Need
15. Six Challenges for Neural Machine Translation
16. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
17. Phrase-Based & Neural Unsupervised Machine Translation
18. SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing
19. Universal Transformers
20. Why Self-Attention? A Targeted Evaluation of Neural Machine Translation Architectures
21. WORD TRANSLATION WITHOUT PARALLEL DATA
22. Bridging the Gap between Training and Inference for Neural Machine Translation
23. deliberation networks: sequence generation beyond one-pass decoding
24. Adaptive Multi-pass Decoder for Neural Machine Translation
25. Dynamic Data Selection for Neural Machine Translation
26. An Empirical Exploration of Curriculum Learning for Neural Machine Translation
27. Dynamic Sentence Sampling for Efficient Training of Neural Machine Translation
28. Analyzing Uncertainty in Neural Machine Translation

### 其他：
1. BLEU: A Method for Automatic Evaluation of Machine Translation
2. Conditional Gated Recurrent Unit with Attention Mechanism
3. An Introductory Survey on Attention Mechanisms in NLP Problems
